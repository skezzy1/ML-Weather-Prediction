import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
df = pd.read_csv('data_preparation/csv/processed_regions/Center/Center_Winter.csv')

# –í–∏–±—ñ—Ä –æ–∑–Ω–∞–∫ —ñ —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó
features = ['Year', 'Month', 'Average Temperature (celsius)',
            'Max Temperature (celsius)', 'Min Temperature (celsius)',
            'Average Wind Speed (m/s)', 'Max Snow Depth (cm)']
target = 'Total Precipitation (mm)'

X = df[features]
y = df[target]

# –†–æ–∑–±–∏—Ç—Ç—è
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# –ü–æ–ª—ñ–Ω–æ–º—ñ–∞–ª—å–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è –∑ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è–º
poly_pipeline = Pipeline([
    ('poly', PolynomialFeatures(degree=3, include_bias=False)),
    ('scaler', StandardScaler()),
    ('regressor', LinearRegression())
])

poly_pipeline.fit(X_train, y_train)
y_pred = poly_pipeline.predict(X_test)

# –ú–µ—Ç—Ä–∏–∫–∏
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# –†–µ–∑—É–ª—å—Ç–∞—Ç–∏
print("üî¢ Polynomial Regression")
print(f"MSE: {mse:.2f}")
print(f"R¬≤ Score: {r2:.2f}")

# –ì—Ä–∞—Ñ—ñ–∫
plt.figure(figsize=(10, 5))
plt.scatter(y_test, y_pred, color='blue', alpha=0.6, label='–ü—Ä–æ–≥–Ω–æ–∑–∏')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='–Ü–¥–µ–∞–ª')
plt.xlabel("–§–∞–∫—Ç–∏—á–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è")
plt.ylabel("–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è")
plt.title("Polynomial Regression: –§–∞–∫—Ç–∏—á–Ω—ñ vs –ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ")
plt.legend()
plt.tight_layout()
plt.show()
